{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Imports and device setup [Runtime: ~5s]\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from typing import Dict, Any, Optional, List\n",
    "import csv\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "# Suppress deprecation warnings from jupyter_client\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', message='.*utcnow.*')\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.callbacks import BaseCallback, CallbackList\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "from sb3_contrib.ppo_mask import MaskablePPO\n",
    "from sb3_contrib.common.wrappers import ActionMasker\n",
    "from sb3_contrib.common.maskable.utils import get_action_masks\n",
    "\n",
    "try:\n",
    "    torch.set_float32_matmul_precision('high')\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "SEED = 42  # Global seed for reproducibility\n",
    "print(f'Using device: {DEVICE}')\n",
    "if DEVICE == 'cuda':\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Improved Scheduling Environment [Runtime: instant]\n",
    "class SchedulingEnvImproved(gym.Env):\n",
    "    metadata = {\"render.modes\": []}\n",
    "    def __init__(self, gpu_config, passing_in_queue, queue):\n",
    "        super().__init__()\n",
    "        self.gpu_config, self.queue, self.passing_in_queue = gpu_config, queue, passing_in_queue\n",
    "        self.gpu_energy_dict, self.total_tardiness, self.num_late_jobs, self.total_energy_consumption = {}, 0.0, 0, 0.0\n",
    "        if self.passing_in_queue and self.queue is not None and 'id' not in self.queue.columns:\n",
    "            self.queue.insert(0, \"id\", self.queue.index + 1)\n",
    "        slices, slice_id = [], 0\n",
    "        for gpu_id, gpu in enumerate(self.gpu_config):\n",
    "            self.gpu_energy_dict[gpu_id] = 0.0\n",
    "            for s in MIG_PROFILE[gpu]:\n",
    "                slices.append([gpu_id, slice_id, int(s[0]), 0]); slice_id += 1\n",
    "        self.slices = slices\n",
    "        self.observation_space = spaces.Dict({\n",
    "            \"next_job\": spaces.Box(0, np.inf, shape=(4,), dtype=np.float32),\n",
    "            \"ready_queue_dist\": spaces.Box(0, 1, shape=(40,), dtype=np.float32),\n",
    "            \"slices\": spaces.Box(low=np.tile(np.array([0,0,1,0],dtype=np.float32),(len(slices),1)),\n",
    "                high=np.tile(np.array([len(self.gpu_config)-1,len(slices)-1,7,1],dtype=np.float32),(len(slices),1)),\n",
    "                shape=(len(slices),4), dtype=np.float32),\n",
    "            \"extras\": spaces.Box(low=0.0, high=1.0, shape=(2,), dtype=np.float32),\n",
    "        })\n",
    "        self.action_space = spaces.Discrete(len(slices))\n",
    "\n",
    "    def reset(self, *, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.gpu_energy_dict, self.total_tardiness, self.num_late_jobs, self.total_energy_consumption = {}, 0.0, 0, 0.0\n",
    "        slices, slice_id = [], 0\n",
    "        for gpu_id, gpu in enumerate(self.gpu_config):\n",
    "            self.gpu_energy_dict[gpu_id] = 0.0\n",
    "            for s in MIG_PROFILE[gpu]:\n",
    "                slices.append([gpu_id, slice_id, int(s[0]), 0]); slice_id += 1\n",
    "        self.slices = slices\n",
    "        if not self.passing_in_queue: self.queue = create_queue().copy()\n",
    "        self.working_queue, self.event_list = [], []\n",
    "        for row in self.queue.itertuples():\n",
    "            self.event_list.append((row.arrivals, 'arrival', row.id, row.deadlines))\n",
    "        self.working_queue.append(self.event_list[0][2]); self.now = self.event_list[0][0]; self.event_list.pop(0)\n",
    "        return self._get_obs(), {}\n",
    "\n",
    "    def _get_obs(self):\n",
    "        working_jobs = self.queue[self.queue['id'].isin(self.working_queue)].copy()\n",
    "        if working_jobs.empty:\n",
    "            deadline_dist = avg_duration_small_dist = avg_duration_medium_dist = avg_duration_large_dist = [0.0]*10\n",
    "        else:\n",
    "            rel_deadline = working_jobs['deadlines'] - self.now\n",
    "            avg_duration_small = (working_jobs['g1_duration'] + working_jobs['g2_duration']) / 2\n",
    "            avg_duration_medium = (working_jobs['g3_duration'] + working_jobs['g4_duration']) / 2\n",
    "            avg_duration_large = working_jobs['g7_duration']\n",
    "            job_bins = [-100, 0, 0.05, 0.2, 0.5, 1, 5, 10, 20, 30, np.inf]\n",
    "            def proportion_in_bins(series, bins):\n",
    "                cut = pd.cut(series, bins=bins, right=False, include_lowest=True)\n",
    "                return cut.value_counts(normalize=True).reindex(pd.IntervalIndex.from_breaks(bins,closed='left'),fill_value=0.0).to_list()\n",
    "            deadline_dist = proportion_in_bins(rel_deadline, job_bins)\n",
    "            avg_duration_small_dist = proportion_in_bins(avg_duration_small, job_bins)\n",
    "            avg_duration_medium_dist = proportion_in_bins(avg_duration_medium, job_bins)\n",
    "            avg_duration_large_dist = proportion_in_bins(avg_duration_large, job_bins)\n",
    "        self.working_queue = sorted(self.working_queue, key=lambda jid: self.queue.loc[self.queue[\"id\"]==jid,\"deadlines\"].iat[0])\n",
    "        next_job_chars = np.array([0,0,0,0], dtype=np.float32)\n",
    "        if len(self.working_queue) > 0:\n",
    "            jr = self.queue.loc[self.queue[\"id\"]==self.working_queue[0]]\n",
    "            next_job_chars = np.array([float((jr['deadlines'].iloc[0]-self.now)/TIME_SCALE),\n",
    "                float(((jr['g1_duration'].iloc[0]+jr['g2_duration'].iloc[0])/2)/TIME_SCALE),\n",
    "                float(((jr['g3_duration'].iloc[0]+jr['g4_duration'].iloc[0])/2)/TIME_SCALE),\n",
    "                float(jr['g7_duration'].iloc[0]/TIME_SCALE)], dtype=np.float32)\n",
    "        free_slices = [s for s in self.slices if s[3]==0]\n",
    "        return {\"next_job\": next_job_chars, \"ready_queue_dist\": np.array(deadline_dist+avg_duration_small_dist+avg_duration_medium_dist+avg_duration_large_dist,dtype=np.float32),\n",
    "            \"slices\": np.array(self.slices,dtype=np.float32), \"extras\": np.array([min(len(self.working_queue)/MAX_QUEUE_SIZE,1.0), len(free_slices)/len(self.slices) if self.slices else 0.0],dtype=np.float32)}\n",
    "\n",
    "    def calculate_energy(self, gpu_id):\n",
    "        busy = [s for s in self.slices if s[0]==gpu_id and s[3]==1]\n",
    "        energy = mig_util_energy.get(sum(s[2] for s in busy)/7, 250) * (self.now - self.gpu_energy_dict[gpu_id])\n",
    "        self.total_energy_consumption += energy; self.gpu_energy_dict[gpu_id] = self.now\n",
    "        return energy\n",
    "\n",
    "    def valid_action_mask(self): return np.array([s[3]==0 for s in self.slices])\n",
    "\n",
    "    def step(self, action):\n",
    "        sel = self.slices[action]; self.slices[action][3] = 1; self.calculate_energy(sel[0])\n",
    "        job_id = self.working_queue.pop(0); jr = self.queue.loc[self.queue[\"id\"]==job_id]\n",
    "        dur = jr[slice_dur_col_match[sel[2]]].iloc[0]\n",
    "        self.event_list.append((self.now+dur, 'completion', job_id, sel[0], sel[1], self.now))\n",
    "        free_slices = [s for s in self.slices if s[3]==0]\n",
    "        if len(self.working_queue)>0 and len(free_slices)>0:\n",
    "            return self._get_obs(), 0.0, False, False, {'action_mask': self.valid_action_mask()}\n",
    "        step_tardiness, step_energy, num_completions = 0.0, 0.0, 0\n",
    "        while True:\n",
    "            self.event_list = sorted(self.event_list, key=lambda x: x[0])\n",
    "            if not self.event_list: break\n",
    "            event = self.event_list.pop(0); self.now = event[0]\n",
    "            if event[1]=='arrival': self.working_queue.append(event[2])\n",
    "            elif event[1]=='completion':\n",
    "                num_completions += 1  # Track actual completions processed\n",
    "                deadline = self.queue[self.queue['id']==event[2]]['deadlines'].iloc[0]\n",
    "                tardiness = max(0.0, self.now-deadline)\n",
    "                if tardiness>0: self.total_tardiness+=tardiness; self.num_late_jobs+=1; step_tardiness+=tardiness\n",
    "                self.slices[event[4]][3] = 0\n",
    "            # Preemption: collect running jobs to reschedule\n",
    "            preempted_events = [e for e in self.event_list if e[1]=='completion']\n",
    "            self.event_list = [e for e in self.event_list if e[1]!='completion']\n",
    "            for e in preempted_events:\n",
    "                elapsed = self.now - e[5]\n",
    "                duration = e[0] - e[5]\n",
    "                # Fix: guard against division by zero\n",
    "                pct = elapsed / duration if duration > 1e-9 else 1.0\n",
    "                idx = self.queue.loc[self.queue['id']==e[2]].index[0]\n",
    "                for col in ['g7_duration','g4_duration','g3_duration','g2_duration','g1_duration']:\n",
    "                    self.queue.loc[idx,col] *= (1-pct)\n",
    "                if self.queue[self.queue['id']==e[2]]['deadlines'].iloc[0]<self.now: step_tardiness+=self.now-self.queue[self.queue['id']==e[2]]['deadlines'].iloc[0]\n",
    "                self.working_queue.append(e[2])\n",
    "            for gid in range(len(self.gpu_config)): step_energy+=self.calculate_energy(gid)\n",
    "            for s in self.slices: s[3]=0\n",
    "            if len(self.working_queue)>0 or len(self.event_list)==0: break\n",
    "        # Fix: use num_completions counter instead of completion_events list\n",
    "        reward = (-step_tardiness-0.0000225*step_energy)/(max(1, num_completions)*1.0000225)\n",
    "        terminated = len(self.event_list)==0 and len(self.working_queue)==0\n",
    "        if terminated:\n",
    "            reward = (-self.total_tardiness-0.0000225*self.total_energy_consumption)/(len(self.queue)*0.0000225+1)\n",
    "            info = {'total_energy': self.total_energy_consumption, 'avg_tardiness': self.total_tardiness/max(1,len(self.queue)), 'num_late_jobs': self.num_late_jobs, 'total_jobs': len(self.queue)}\n",
    "        else: info = {'total_energy': self.total_energy_consumption}\n",
    "        info['action_mask'] = self.valid_action_mask()\n",
    "        return self._get_obs(), reward, terminated, False, info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Heuristic baselines [Runtime: ~30s for quick test, ~5min for full eval]\n",
    "SLICE_SIZE_IDX = 2\n",
    "\n",
    "def heuristic_select_action(obs, mask, heuristic=\"EFT\"):\n",
    "    \"\"\"Select action based on heuristic rule.\n",
    "    \n",
    "    Heuristics:\n",
    "    - EFT: Earliest Finish Time - prefer slices that minimize completion time\n",
    "    - ENERGY_MIN: Prefer smaller slices for lower energy consumption\n",
    "    - FIFO: First available slice\n",
    "    - EDD: Earliest Due Date - uses largest slice for urgent jobs (already sorted by deadline)\n",
    "    \"\"\"\n",
    "    slices, next_job = obs[\"slices\"], obs[\"next_job\"]\n",
    "    dur_small, dur_med, dur_large = next_job[1], next_job[2], next_job[3]\n",
    "    candidates = []\n",
    "    for idx, s in enumerate(slices):\n",
    "        if not mask[idx]: continue\n",
    "        size = int(s[SLICE_SIZE_IDX])\n",
    "        est = dur_small if size in (1,2) else (dur_med if size in (3,4) else dur_large)\n",
    "        if heuristic == \"EFT\": \n",
    "            score = est  # prefer smallest estimated finish time\n",
    "        elif heuristic == \"ENERGY_MIN\": \n",
    "            score = est * (0.5 + 0.1*size)  # prefer smaller slices\n",
    "        elif heuristic == \"FIFO\": \n",
    "            score = idx  # first available\n",
    "        elif heuristic == \"EDD\": \n",
    "            # EDD prefers largest slice (fastest) for urgent jobs\n",
    "            score = -size  # prefer larger slice for faster completion\n",
    "        else: \n",
    "            score = np.random.rand()\n",
    "        candidates.append((score, idx))\n",
    "    if not candidates:\n",
    "        avail = np.where(mask)[0]\n",
    "        return int(avail[0]) if len(avail) else 0\n",
    "    candidates.sort(key=lambda x: x[0])\n",
    "    return int(candidates[0][1])\n",
    "\n",
    "def run_heuristic_eval(n_queues=10, heuristic=\"EFT\", seed=42, hour_range=24, verbose=True):\n",
    "    \"\"\"Evaluate a heuristic on n_queues random job queues.\n",
    "    \n",
    "    Args:\n",
    "        n_queues: Number of queues to evaluate\n",
    "        heuristic: One of \"EFT\", \"ENERGY_MIN\", \"FIFO\", \"EDD\"\n",
    "        seed: Random seed for reproducibility\n",
    "        hour_range: Hours of jobs to generate (24 = ~800 jobs, 4 = ~130 jobs)\n",
    "        verbose: Print progress\n",
    "    \"\"\"\n",
    "    np.random.seed(seed); random.seed(seed)\n",
    "    total_energy, avg_tardiness, late_fractions = [], [], []\n",
    "    start = time.time()\n",
    "    for i in range(n_queues):\n",
    "        queue = create_queue(hour_range=hour_range).drop('id', axis=1)\n",
    "        env = ActionMasker(SchedulingEnvImproved(GPU_CONFIG, True, queue.copy()), mask_fn)\n",
    "        obs, _ = env.reset(); done = False\n",
    "        step_count = 0\n",
    "        while not done:\n",
    "            act = heuristic_select_action(obs, get_action_masks(env), heuristic)\n",
    "            obs, reward, terminated, truncated, info = env.step(act)\n",
    "            done = terminated or truncated\n",
    "            step_count += 1\n",
    "            if done:\n",
    "                total_energy.append(info['total_energy']); avg_tardiness.append(info['avg_tardiness'])\n",
    "                late_fractions.append(info['num_late_jobs']/info['total_jobs'])\n",
    "        if verbose:\n",
    "            print(f\"  Queue {i+1}/{n_queues}: {info['total_jobs']} jobs, {step_count} steps, tardiness={info['avg_tardiness']:.4f}\")\n",
    "    elapsed = time.time() - start\n",
    "    if verbose:\n",
    "        print(f\"  Completed in {elapsed:.1f}s\")\n",
    "    return {'method': f'Heuristic-{heuristic}', 'mean_energy': float(np.mean(total_energy)), 'std_energy': float(np.std(total_energy)),\n",
    "        'mean_tardiness': float(np.mean(avg_tardiness)), 'std_tardiness': float(np.std(avg_tardiness)), 'mean_late_fraction': float(np.mean(late_fractions)), 'n_queues': n_queues}\n",
    "\n",
    "# Quick sanity test with SHORT queues (4 hours = ~130 jobs instead of 24 hours = ~800 jobs)\n",
    "print(\"Quick sanity test with EFT heuristic (4-hour queues)...\")\n",
    "eft_result = run_heuristic_eval(n_queues=1, heuristic=\"EFT\", hour_range=4)\n",
    "print(f\"✓ EFT test passed: tardiness={eft_result['mean_tardiness']:.4f}, energy={eft_result['mean_energy']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicted Improvement Analysis\n",
    "\n",
    "## Bug Fixes Applied:\n",
    "1. **Reward calculation** - Now correctly tracks completion count during event loop\n",
    "2. **EDD heuristic** - Fixed to prefer larger slices for urgent jobs (faster completion)\n",
    "3. **Division by zero** - Guarded preemption percentage calculation\n",
    "4. **Reproducibility** - Added seeds for deterministic training\n",
    "\n",
    "## Expected Improvements Over Baseline\n",
    "\n",
    "| Improvement | Impact on Tardiness | Impact on Energy | Confidence |\n",
    "|-------------|---------------------|------------------|------------|\n",
    "| **LR Annealing** (3e-4 → 0) | -5% to -10% | ~0% | High |\n",
    "| **Entropy Decay** (0.0005 → 0.0001) | -3% to -8% | -2% to -5% | Medium |\n",
    "| **Deeper Network** ([256,256] → [256,256,128]) | -5% to -15% | -3% to -8% | Medium |\n",
    "| **Larger Batch** (2048 → 4096) | -2% to -5% | ~0% | Medium |\n",
    "| **More Epochs** (5 → 8) | -3% to -7% | -1% to -3% | Medium |\n",
    "| **Tighter Clip** (0.2 → 0.15) | -2% to -5% | ~0% | Low |\n",
    "| **Extras Observation** (queue_len, free_slices) | -5% to -10% | -3% to -7% | Medium |\n",
    "| **Reward Bug Fix** | -5% to -15% | -5% to -10% | High |\n",
    "\n",
    "## Overall Prediction\n",
    "\n",
    "**Expected improvement over baseline:**\n",
    "- **Tardiness**: **15-30% reduction** (from ~X to ~0.7-0.85X)\n",
    "- **Energy**: **5-15% reduction** (from ~Y to ~0.85-0.95Y)\n",
    "- **Late Job Fraction**: **10-25% reduction**\n",
    "\n",
    "*Note: These are estimates based on typical RL scheduling improvements. Actual results depend on queue characteristics and randomness.*\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
